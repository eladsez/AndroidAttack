# Copyright (C) 2017  Luca Massarelli
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from classification.Classifier import Classifier
from util.Logger import Logger;
import numpy as np
import os
import pickle
import random
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import f1_score
from sklearn.feature_selection import mutual_info_classif
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectPercentile


##This class implements all method that handle the construction of a malware classification
# model and the evaluation of its performances.

class MalwareClassifier:
    logger = ""
    classifier = ""

    # The constructor
    def __init__(self):
        self.logger = Logger(3)
        self.classifier = Classifier()

    # This method train the selected classifier.
    # It returns the trained model.
    # @param trainData = data for the training
    # @param trainTarget = label for the training data
    # @param classifier = classifier to use
    def trainClassifier(self, trainData, trainTarget, classifier):
        svc = ""
        if classifier == 'linear':
            svc = self.classifier.svmLinear(trainData, trainTarget)
        if classifier == 'sgdSvm':
            svc = self.classifier.sgdSvm(trainData, trainTarget)
        if classifier == 'rbf':
            svc = self.classifier.svmRBF(trainData, trainTarget)
        if classifier == 'poly':
            svc = self.classifier.svmPoly(trainData, trainTarget)
        if classifier == 'forest':
            svc = self.classifier.randomForest(trainData, trainTarget)
        return svc

    # This method performs the feature.txt selection and then the training of the classifier.
    # It choose the feature.txt subset based on the best accuracy on training stage. Finally,
    # it apply the classification model to the test data.
    # It return four object:
    # - pred = list of the prediction of the model
    # - bestSvc = model used for prediction
    # - selector = selector of the features
    # - pca = pca object for the dimensionality reduction of the features
    # @param trainData = data for training the classifier
    # @param trainTarget = label for the training
    # @param testData = data for testing
    # @param classifier = type of the classifier to use
    def selectTrainEvaluate(self, trainData, trainTarget, testData, classifier):
        feature_grid = [10, 20, 30, 40, 50, 60, 70]
        scoreMax = 0
        bestSelector = ' '
        bestPca = ' '
        bestSvc = ' '
        bestPerc = 0
        for item in feature_grid:
            self.logger.log("INFO", "TRYING FEATURE PERCENTILE " + str(item))
            selector = SelectPercentile(mutual_info_classif, percentile=item)
            trainDataSel = selector.fit_transform(trainData, trainTarget)
            pca = PCA(n_components=0.99, svd_solver='full')

            trainDataSel = pca.fit_transform(trainDataSel)

            result = self.trainClassifier(trainDataSel, trainTarget, classifier)

            self.logger.log("INFO", "DONE FEATURE PERCENTILE " + str(item) + " SCORE: " + str(result["score"]))

            if (result["score"] > scoreMax):
                bestPerc = item;
                scoreMax = result["score"]
                bestSelector = selector
                bestPca = pca
                bestSvc = result["svc"]

        self.logger.log("INFO", "DONE FEATURE CROSS VALIDATION")
        self.logger.log("INFO", "BEST RESULT WITH " + str(bestPerc) + " PERCENTILE")
        testDataSel = bestSelector.transform(testData)
        testData = bestPca.transform(testDataSel)
        pred = bestSvc.predict(testData)
        return pred, bestSvc, bestSelector, bestPca

    # This method compute the statistic of the model over a set of predicted label
    # It return an object with 7 keys:
    #	- accuracyMean: accuracy value
    #   - accuracyStd: fixed to 0
    # 	- recall: recall
    # 	- precision: precision
    # 	- f1: f1 score
    # 	- falsePositiveRate: false positive rate
    #	- N: num of classes
    # @param trueLabel = real label of the test set
    # @param predictedLabel = predicted label over the test set
    def calculateStatistic(self, trueLabel, predictedLabel):
        accuracy = accuracy_score(predictedLabel, trueLabel, normalize=True)
        recall = recall_score(predictedLabel, trueLabel, average=None)
        precision = precision_score(predictedLabel, trueLabel, average=None)
        f1 = f1_score(predictedLabel, trueLabel, average=None)
        falsePositiveRate = self.falsePositiveRate_score(predictedLabel, trueLabel)
        return ({"accuracyMean": accuracy, "accuracyStd": 0, "recall": recall, "precision": precision,
                 "f1": f1, "falsePositiveRate": falsePositiveRate, "N": np.unique(trueLabel).shape[0]})

    # This methods compute the false positive rate
    # it returns a floating number
    # @param x = real label
    # @param y = predicted label
    def falsePositiveRate_score(self, x, y):
        cnf_matrix = confusion_matrix(x, y)
        fp_rate = np.empty([0])
        for i in range(0, cnf_matrix.shape[0]):
            it = np.nditer(cnf_matrix, flags=['multi_index'], op_flags=['writeonly'])
            FP = 0
            TN = 0
            FN = 0
            for x in it:
                if it.multi_index[0] == i and it.multi_index[1] != i:
                    FN += x
                elif it.multi_index[0] != i and it.multi_index[1] == i:
                    FP += x
                elif it.multi_index[0] != i and it.multi_index[1] != i:
                    TN += x
            fp_rate = np.append(fp_rate, FP / (FP + TN))
        return fp_rate

    # This method remove from data all features vectors of package that has minus than
    # threshold samples in the dataset
    # @param data = matrix of data to clean
    # @param threshold = threshold for deleting data
    def cleanClass(self, datas, threshold):
        data = datas["data"]
        family = datas["family"]
        package = datas["package"]
        familyStr = datas["familyStr"]
        packageStr = datas["packageStr"]
        numOfLabel = np.max(family)
        for i in range(0, int(numOfLabel) + 1):
            a = np.where(family == i)
            p = np.unique(package[a])
            if p.shape[0] < threshold:
                data = np.delete(data, a[0], axis=0)
                family = np.delete(family, a[0], axis=0)
                package = np.delete(package, a[0], axis=0)
                familyStr = np.delete(familyStr, a[0], axis=0)
                packageStr = np.delete(packageStr, a[0], axis=0)
        return ({'data': data, 'package': package, 'family': family,
                 'familyEncoder': datas["familyEncoder"], 'packetEncoder': datas["packetEncoder"],
                 'familyStr': familyStr, 'packetStr': packageStr})

    # This method select only data that own to families in familyList param
    # @param data = data obj
    # @param familyList = list of family to select
    def selDataByFamily(self, datas, familyList):
        new_data = {}
        dati = np.zeros([0, np.shape(datas["data"])[1]])
        family = np.empty([0])
        package = np.empty([0])
        packetEncoder = datas["packetEncoder"]
        familyEncoder = datas["familyEncoder"]
        packetStr = []
        familyStr = []
        for item in familyList:
            i = familyEncoder.transform([item])
            sel = np.where(datas["family"] == i)
            for k in sel[0]:
                dati = np.vstack([dati, datas["data"][k]])
                family = np.append(family, datas["family"][k])
                package = np.append(package, datas["package"][k])
                packetStr.append(datas["packageStr"][k])
                familyStr.append(datas["familyStr"][k])
        return ({'data': dati, 'package': package, 'family': family,
                 'familyEncoder': familyEncoder, 'packetEncoder': packetEncoder,
                 'familyStr': familyStr, 'packageStr': packetStr})

    ## This method split the data in training and test set
    # according to the package.
    # @param data = matrix data to split
    # @param label = list of label of data (family)
    # @param package = list of package of data
    # @param testSize = percentile of the test size
    def train_test_split(self, data, label, package, testSize):
        families = np.unique(label)
        trainData = np.empty([0, np.shape(data)[1]])
        testData = np.empty([0, np.shape(data)[1]])
        trainTarget = np.empty([0])
        testTarget = np.empty([0])
        for family in families:
            fam_idx = np.where(label == family)
            package_uniq = np.unique(package[fam_idx])
            num_packet = np.shape(package_uniq)[0]
            test_pkt = round(num_packet * testSize)
            train_pkt = num_packet - test_pkt
            for i in range(0, train_pkt):
                pack_chosen = random.choice(package_uniq)
                package_uniq = np.delete(package_uniq, np.where(package_uniq == pack_chosen))
                data_idx = np.where(package == pack_chosen)[0]
                trainData = np.vstack((trainData, data[data_idx, :]))
                trainTarget = np.hstack((trainTarget, label[data_idx]))
            for i in range(0, test_pkt):
                pack_chosen = random.choice(package_uniq)
                package_uniq = np.delete(package_uniq, np.where(package_uniq == pack_chosen))
                data_idx = np.where(package == pack_chosen)[0]
                testData = np.vstack((testData, data[data_idx, :]))
                testTarget = np.hstack((testTarget, label[data_idx]))
        return trainData, testData, trainTarget, testTarget

    # This method print the list of all the data in the datas object structure
    # @param datas = data object structure
    def listData(self, datas):
        packet, index = np.unique(datas["packetStr"], True)
        count = 1;
        families = []
        for p, i in zip(packet, index):
            f = datas["familyStr"][i]
            print("{} -- Packet: {}, Family: {}".format(count, p, f))
            families.append(f)
            count += 1;
        family, index, indices, occurence = np.unique(families, True, True, True)
        count = 1;
        for f, o in zip(family, occurence):
            f = f.replace('\\r\\n\'', '')
            print("{} -- Family: {}, Occurrence: {}".format(count, f, o))
            count += 1

    ##This methods handles the execution of the classification experiment
    # It return an "experiment dictionary" with several keys:
    # - accuracyMean: average value of the accuracy
    # - accuracyStd: standard deviation of the accuracy
    # - accuracy: accuracy value for each experiment
    # - recall: recall value for each experiment
    # - precision: precision value for each experiment
    # - f1: f1 score value for each experiment
    # - falsePositiveRate: false positive rate value for each experiment
    # - y_pred: last prediction
    # - y_test: real label of the test set
    # - cnf_matrix: average confusion matrix
    # - N: num of classes
    # - svc: classifier model
    # - classes: name of classes
    # @param dati = data object structure
    # @param numRep = num of independent repetition of the experiment
    # @param classifierName = name of the classifier to use
    def doExperiment(self, dati, numRep, classifierName):

        samples = dati["data"];
        family = dati["family"];
        package = dati["package"];

        numClass = np.unique(family).shape[0]
        accuracy = np.empty([0])
        recall = np.empty([numClass, 0]);
        precision = np.empty([numClass, 0]);
        f1 = np.empty([numClass, 0]);
        falsePositiveRate = np.empty([numClass, 0]);

        for i in range(0, numRep):
            self.logger.log("INFO", "Repetition number: " + str(i))

            trainData, testData, trainTarget, testTarget = self.train_test_split(samples, family, package, 0.2)
            pred, svc, bestSelector, bestPca = self.selectTrainEvaluate(trainData, trainTarget, testData,
                                                                        classifierName);
            accuracy = np.hstack((accuracy, accuracy_score(pred, testTarget, normalize=True)));
            recall = np.hstack((recall, recall_score(pred, testTarget, average=None).reshape(numClass, 1)));
            precision = np.hstack((precision, precision_score(pred, testTarget, average=None).reshape(numClass, 1)));
            f1 = np.hstack((f1, f1_score(pred, testTarget, average=None). \
                            reshape(numClass, 1)));
            falsePositiveRate = np.hstack((falsePositiveRate, self. \
                                           falsePositiveRate_score(pred, testTarget). \
                                           reshape(numClass, 1)));
            if ("cnf_matrix" not in locals()):
                cnf_matrix = confusion_matrix(testTarget, pred)
            else:
                cnf_matrix = cnf_matrix + confusion_matrix(testTarget, pred)
            self.logger.log("INFO", "Accuracy: " + str(accuracy_score(pred, testTarget, normalize=True)))

        u = np.unique(testTarget);
        l = []
        for item in u:
            l.append(dati["familyEncoder"].inverse_transform(int(item)));

        return ({"accuracyMean": np.mean(accuracy), "accuracyStd": np.std(accuracy),
                 "accuracy": accuracy, "recall": recall, "precision": precision,
                 "f1": f1, "falsePositiveRate": falsePositiveRate, "y_pred": pred,
                 "y_test": testTarget, "cnf_matrix": cnf_matrix, "N": numClass, "svc": svc,
                 "classes": l})

    ##This method prepare the execution of the experiment, launch it and save result
    # in a file.
    # @param datas = data object to use
    # @param sampleThreshold = threshold to choose family
    # @param numOfRepetition = number of repetition of the experiment
    # @param classifierName = classifier to use
    # @param experimentName = name of the experiment. result file will be name
    # [experimentName]_i.pkl where is an incrementing index
    def prepareAndRunExperiment(self, datas, numOfRepetition, classifierName, experimentName):
        accuracyMean = np.empty([0])
        accuracyStd = np.empty([0])
        res = datas
        label = res["family"]
        package = res["package"]
        data = res["data"]

        self.logger.log("INFO", "starting classification experiment: " + experimentName)
        self.logger.log("INFO", "repetition: " + str(numOfRepetition))
        self.logger.log("INFO", "num of data vector: " + str(data.shape))
        self.logger.log("INFO", "num of package: " + str(np.unique(res["package"]).shape))
        self.logger.log("INFO", "num of family: " + str(np.unique(res["family"]).shape))
        result = self.doExperiment(res, numOfRepetition, classifierName)

        result["numDataVector"] = data.shape
        result["numPackage"] = np.unique(res["package"]).shape
        result["numFamily"] = np.unique(res["family"]).shape
        cnt = 0
        filename = experimentName + "_" + str(cnt) + ".pkl"
        while os.path.exists(filename):
            cnt += 1
            filename = experimentName + "_" + str(cnt) + ".pkl"

        with open(filename, 'wb') as output:
            pickle.dump(result, output, pickle.HIGHEST_PROTOCOL)
        self.logger.log("INFO", "Acuracy mean: {:10.2f} STD: {:10.2f} "
                        .format(result['accuracyMean'], result['accuracyStd']))
        self.logger.log("INFO", "Data saved on file: " + filename)

        accuracyMean = np.append(accuracyMean, result['accuracyMean'])
        accuracyStd = np.append(accuracyStd, result['accuracyStd'])
        return {"accuracyMean": accuracyMean, "accuracyStd": accuracyStd}
